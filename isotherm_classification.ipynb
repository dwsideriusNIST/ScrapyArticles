{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification: Isotherm Data, No Data\n",
    "#Import statements\n",
    "#everything is the same as 3 group classification except for the labels\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "#Imports from Scikit learn library\n",
    "import sklearn\n",
    "\n",
    "#Vectorize the text to frequencies\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#splits training and testing articles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Algorithms used\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#tells accuracy, f-score, precision, recall\n",
    "from sklearn import metrics\n",
    "\n",
    "#Imports from Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_index = []\n",
    "text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathacs = '/Users/juliachotoo/ScrapyArticles/scrapedjson/acs2/'\n",
    "\n",
    "for filename in os.listdir(pathacs):\n",
    "    with open(pathacs + filename, 'r'):\n",
    "        resultacs = json.load(open(pathacs + filename, mode='r'))\n",
    "        doi_index.append(resultacs['doi'])\n",
    "        text.append(resultacs['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathspr = '/Users/juliachotoo/ScrapyArticles/scrapedjson/spr2/'\n",
    "\n",
    "for filename in os.listdir(pathspr):\n",
    "    with open(pathspr + filename, 'r'):\n",
    "        resultspr = json.load(open(pathspr + filename, mode='r'))\n",
    "        doi_index.append(resultspr['doi'])\n",
    "        text.append(resultspr['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "pathlabels = '/Users/juliachotoo/ScrapyArticles/simpledatalabels.csv'\n",
    "labels = []\n",
    "\n",
    "with open(pathlabels, 'r') as csvfile:\n",
    "    resultlabels = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in resultlabels:\n",
    "        labels.append(', '.join(row))\n",
    "\n",
    "labels[0] = labels[0].replace('\\ufeff', '')\n",
    "print(labels)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data labels\n",
      "0  10.1021/ic501413r Metal–organic frameworks (MO...      0\n",
      "1  10.1021/jp102881e  Top of PageAbstractIntroduc...      0\n",
      "2  10.1021/acs.analchem.5b00391 Metal–organic fra...      0\n",
      "3  10.1021/ct400255c Top of PageAbstractIntroduct...      1\n",
      "4  10.1021/ie071645b  Top of PageAbstract1. Intro...      0\n",
      "5  10.1021/ic502478u Metal–organic frameworks (MO...      0\n",
      "6  10.1021/cm4034319 Top of PageAbstractIntroduct...      0\n",
      "7  10.1021/acs.langmuir.5b04185 In the original a...      1\n",
      "8  10.1021/ic060568u  Top of PageAbstractIntroduc...      1\n",
      "9  10.1021/ie500310c Top of PageAbstractIntroduct...      0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'data': text, 'labels': labels})\n",
    "print(df.loc[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313,)\n",
      "(313,)\n",
      "(234,)\n",
      "(79,)\n",
      "(234,)\n",
      "(79,)\n"
     ]
    }
   ],
   "source": [
    "#tells where the data (X) is coming from and labels (y)\n",
    "#shape tells the number in each\n",
    "X = df.data\n",
    "y = df[df.columns[1]]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#train-test split of articles, 75% training - 25% testing\n",
    "#shape shows number in each\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<79x44773 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 64936 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmer puts all the words with the same stem (e.g run, runner, running) to count toward that stem's frequency\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "#Vectorizes text from words to numbers\n",
    "#uses stemmer and removes stopwords (words that don't add to the meaning)\n",
    "vect = CountVectorizer(tokenizer=stemming_tokenizer, stop_words=stopwords.words('english'))\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train) #fit (learning from words provided) and transform training data\n",
    "\n",
    "\n",
    "X_test_dtm = vect.transform(X_test) #only transform testing data (fits words from training data that computer already knows)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried this but it makes the accuracy lower for all algorithms so I took it out\n",
    "#It weights frequencies according to how long each article is to make the data more uniform\n",
    "\n",
    "#tf_transformer = TfidfTransformer()\n",
    "#X_train_tf = tf_transformer.fit_transform(X_train_dtm)\n",
    "#X_test_tf = tf_transformer.transform(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes Algorithm\n",
    "#the way to run each algorithm and get metrics is the same for all four\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.91 ms, sys: 2.67 ms, total: 8.58 ms\n",
      "Wall time: 6.55 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit algorithm (nb) to training data only\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have the computer predict the labels for the testing set\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87341772151898733"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How accurate the predictions were\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  0],\n",
       "       [10,  7]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows how many articles classified correctly for each group and when classified wrong which group were they\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.86111111,  1.        ]),\n",
       " array([ 1.        ,  0.41176471]),\n",
       " array([ 0.92537313,  0.58333333]),\n",
       " array([62, 17]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows precision, recall, and f-score for each group\n",
    "metrics.precision_recall_fscore_support(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Algorithm\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 106 ms, sys: 2.82 ms, total: 109 ms\n",
      "Wall time: 107 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class2 = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86075949367088611"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59,  3],\n",
       "       [ 8,  9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.88059701,  0.75      ]),\n",
       " array([ 0.9516129 ,  0.52941176]),\n",
       " array([ 0.91472868,  0.62068966]),\n",
       " array([62, 17]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_test, y_pred_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 3.87 ms, total: 240 ms\n",
      "Wall time: 238 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Classifier Algorithm\n",
    "svcm = SVC(kernel='linear')\n",
    "%time svcm.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class3 = svcm.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92405063291139244"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61,  1],\n",
       "       [ 5, 12]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.92424242,  0.92307692]),\n",
       " array([ 0.98387097,  0.70588235]),\n",
       " array([ 0.953125,  0.8     ]),\n",
       " array([62, 17]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_test, y_pred_class3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=25, random_state=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree with AdaBoost Algorithm\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm='SAMME', n_estimators=25)\n",
    "clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class4 = clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92405063291139244"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61,  1],\n",
       "       [ 5, 12]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.92424242,  0.92307692]),\n",
       " array([ 0.98387097,  0.70588235]),\n",
       " array([ 0.953125,  0.8     ]),\n",
       " array([62, 17]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_test, y_pred_class4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112    10.1021/jp9006747   Top of PageAbstractIntrodu...\n",
       "Name: data, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can look at which algorithms classified incorrectly \n",
    "X_test[y_test < y_pred_class4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310    https://doi.org/10.1007/s10934-011-9494-5 1 In...\n",
       "227    10.1021/jp3046356 Top of PageAbstractIntroduct...\n",
       "294    https://doi.org/10.1007/s10450-013-9527-2 1 In...\n",
       "236    10.1021/acs.langmuir.5b01171 Top of PageAbstra...\n",
       "267    10.1021/la035556p  Top of PageAbstractIntroduc...\n",
       "293    https://doi.org/10.1007/s10450-016-9793-x 1 In...\n",
       "4      10.1021/ie071645b  Top of PageAbstract1. Intro...\n",
       "161    10.1021/jp411536d Top of PageAbstractIntroduct...\n",
       "70     10.1021/acs.inorgchem.5b00722 Top of PageAbstr...\n",
       "188    10.1021/cg500269h Top of PageAbstractIntroduct...\n",
       "Name: data, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can see which algorithms predicted into class 1 (multicomponent)\n",
    "X_test[y_pred_class4 == '1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
